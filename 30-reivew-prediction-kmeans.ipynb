{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disneyland_TreeMethods.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python373jvsc74a57bd077b122b46b811bf25a94c2daf71b0b6b5d8e93bff1d9be67645d638b69bd8036",
      "display_name": "Python 3.7.3 64-bit ('ds21_capstone': virtualenvwrapper)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "source": [
        "# Modeling - Tree Methods + K-Means\n",
        "---\n",
        "\n",
        "Buiding off of the tree-based modeling from the other notebook `20-review-prediction.ipynb`, we will try and predict the review rating (1, 2, 3, 4, 5) from the review's text and other features.\n",
        "\n",
        "One of our methods includes K-Means clustering the reviews, based on the review text, and using that clustering a feature in our random forest and decision tree classifiers"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Package Installation + Setup\n",
        "---\n",
        "\n",
        "Because multiple team members used google drive, please check the drive path in each notebook. They might be slightly different!"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00OrJ2G5ouIZ",
        "outputId": "a52ce204-61ab-4c35-dfa4-7486034120a9"
      },
      "source": [
        "# Install PySpark pacakges and set environment variables to use Spark on Colab\n",
        "!pip install pyspark \n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "\n",
        "!pip install pysparkling\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvP6N998pMkp",
        "outputId": "76f173b3-446e-4941-f23d-caa130757c2d"
      },
      "source": [
        "# Google Drive Authentication\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLt8czf0pPqn",
        "outputId": "97303213-e3b3-462c-d3c6-2043d3d67ef6"
      },
      "source": [
        "# PROJECT PATH\n",
        "cur_path = \"/content/drive/MyDrive/Colab Notebooks/BigDataScaling/Project/\"\n",
        "os.chdir(cur_path)\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/BigDataScaling/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import VectorAssembler and Vectors\n",
        "\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, Word2Vec\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
        "\n",
        "# PySpark SQL\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import substring\n",
        "from pyspark.sql.types import StringType,BooleanType,DateType,IntegerType\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "from pyspark.sql.functions import *\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "# NLP / PySparkling\n",
        "from pysparkling import *  \n",
        "from nltk.corpus import stopwords  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93k5XjrCpMZQ"
      },
      "source": [
        "# create a spark session\n",
        "spark = SparkSession.builder.appName('tree').getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Load + Clean Data\n",
        "---\n",
        "\n",
        "Load the Disneyland Reviews CSV and clean year/month and branch columns"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scy4LDz6py4_"
      },
      "source": [
        "# Load  data\n",
        "data = spark.read.csv(cur_path + 'DisneylandReviews.csv',inferSchema=True,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rJyg_TbzAwv"
      },
      "source": [
        "# Create Year, Month column\n",
        "data = data.withColumn('Year', substring('Year_Month', 1,4))\n",
        "data = data.withColumn('Month', substring('Year_Month', 6, len('Year_Month')))\n",
        "# Clean Branch Name\n",
        "data = data.withColumn('Branch_Clean', substring('Branch', 12, 50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpohLhNf01YQ",
        "outputId": "1f02dd22-5594-423a-cac1-46ae64ab07ee"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Review_ID: integer (nullable = true)\n",
            " |-- Rating: integer (nullable = true)\n",
            " |-- Year_Month: string (nullable = true)\n",
            " |-- Reviewer_Location: string (nullable = true)\n",
            " |-- Review_Text: string (nullable = true)\n",
            " |-- Branch: string (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            " |-- Month: string (nullable = true)\n",
            " |-- Branch_Clean: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4FhWcBIz5G4",
        "outputId": "75664004-f65a-49b0-f9d9-240ea3ad9241"
      },
      "source": [
        "# data preview\n",
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------+----------+--------------------+--------------------+-------------------+----+-----+------------+\n",
            "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|Year|Month|Branch_Clean|\n",
            "+---------+------+----------+--------------------+--------------------+-------------------+----+-----+------------+\n",
            "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|2019|    5|    HongKong|\n",
            "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|2019|    3|    HongKong|\n",
            "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|2019|    3|    HongKong|\n",
            "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|2018|    9|    HongKong|\n",
            "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|2019|    1|    HongKong|\n",
            "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|2019|    4|    HongKong|\n",
            "|670033848|     5|   2018-11|           Hong Kong|There is nothing ...|Disneyland_HongKong|2018|   11|    HongKong|\n",
            "+---------+------+----------+--------------------+--------------------+-------------------+----+-----+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o518NgqI1FJa"
      },
      "source": [
        "# Change Year/Month to integer\n",
        "data = data.withColumn('Year', col(\"Year\").cast(IntegerType()))\n",
        "data = data.withColumn('Month', col('Month').cast(IntegerType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Drop Mising Data\n",
        "---\n",
        "\n",
        "Only ~2.6k reocrds (6%) were missing a review date. As a result, we are going to drop them"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJcI8PiuDTIl",
        "outputId": "0574d3c6-9365-42dc-a5ce-2154fa71698c"
      },
      "source": [
        "data.select([count(when(col('Year').isNull(),True))]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------+\n",
            "|count(CASE WHEN (Year IS NULL) THEN true END)|\n",
            "+---------------------------------------------+\n",
            "|                                         2613|\n",
            "+---------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tVXX3-ZEeqd"
      },
      "source": [
        "# drop that data\n",
        "data = data.na.drop('any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oszX-WEXEH9c",
        "outputId": "631fdd44-1341-4875-fddd-a3aa88c6313b"
      },
      "source": [
        "# Confirming dropped records\n",
        "data.select([count(when(col('Year').isNull(),True))]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------+\n",
            "|count(CASE WHEN (Year IS NULL) THEN true END)|\n",
            "+---------------------------------------------+\n",
            "|                                            0|\n",
            "+---------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "## Encoding String Features\n",
        "---\n",
        "\n",
        "Using a `StringIndexer` ([link](https://spark.apache.org/docs/latest/ml-features#stringindexer)) to encode the Branch name and the reviewer's Country"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# deal with string features\n",
        "indexer_location = StringIndexer(inputCol=\"Reviewer_Location\", outputCol=\"LocationIndex\")\n",
        "indexer_branch = StringIndexer(inputCol='Branch_Clean', outputCol=\"BranchIndex\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "NBJaQoWwuBfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibyMtuk2yqWP"
      },
      "source": [
        "data_fixed = indexer_location.fit(data).transform(data)\n",
        "data_fixed = indexer_branch.fit(data_fixed).transform(data_fixed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Tokenize Review Text\n",
        "---\n",
        "\n",
        "To predict a review's rating from their text, we have are going tokenize the reviews and remove stop words. We can then creat a TFIDF with a min-frequecy of 6 to remove any sparse/rarely used words.\n",
        "\n",
        "The output hash of our cleaned, tokenized review text (`hashtf`) is then fit by a `Word2Vec` model and fed into a k-means clustering model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9yrq7hkXWwC"
      },
      "source": [
        "\n",
        "tokenizer = \\\n",
        "    RegexTokenizer(inputCol='Review_Text', outputCol = 'tokenized_words', pattern=\"\\\\W+\", minTokenLength = 3)\n",
        "\n",
        "text_data = tokenizer.transform(data_fixed)\n",
        "remover = StopWordsRemover(inputCol='tokenized_words', outputCol = 'word_tokens')\n",
        "text_data = remover.transform(text_data)\n",
        "\n",
        "hashtf = HashingTF(numFeatures=2**16, inputCol=\"word_tokens\", outputCol='tf')\n",
        "idf = IDF(inputCol='tf', outputCol=\"tfidf\", minDocFreq=5) #minDocFreq: remove sparse terms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4bNWwovccYy"
      },
      "source": [
        "text_data = hashtf.transform(text_data.select('word_tokens'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVep7ainjNO"
      },
      "source": [
        "word2Vec = Word2Vec(vectorSize=5, seed=42, inputCol=\"word_tokens\", outputCol=\"sentence\")\n",
        "\n",
        "text = text_data.select('word_tokens')\n",
        "model = word2Vec.fit(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## K-Means Clustering with tokenized review text"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sPSduLsvnSH"
      },
      "source": [
        "text_data = model.transform(text_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r64UYkkAa53T"
      },
      "source": [
        "assembler_kmeans = VectorAssembler(\n",
        "  inputCols=['sentence'],\n",
        "              outputCol=\"features\")\n",
        "\n",
        "kmeans_df = assembler_kmeans.transform(text_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lmio3jEXoOF"
      },
      "source": [
        "# intialize and fit k-means clustering model (2 clusters)\n",
        "kmeans = KMeans(featuresCol='features').setK(2).setSeed(1)\n",
        "km_model2 = kmeans.fit(kmeans_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA__umFMcIou",
        "outputId": "fc828355-8026-43b3-bd5c-5a0c695e2484"
      },
      "source": [
        "# Show predictions from our dataset\n",
        "predictions2 = km_model2.transform(kmeans_df)\n",
        "predictions2.groupBy('prediction').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         1|17553|\n",
            "|         0|22490|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQnOKXdjffb"
      },
      "source": [
        "w = Window.orderBy(lit(1))\n",
        "data_fixed = data_fixed.withColumn(\"rn\", row_number().over(w)-1)\n",
        "predictions2 = predictions2.withColumn(\"rn\", row_number().over(w)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQwJmlfVdfeY"
      },
      "source": [
        "data_fixed = data_fixed.join(predictions2,[\"rn\"]).drop(\"rn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkr__ZRclxNd",
        "outputId": "1325a5b9-8e1f-40a5-98ed-14d51f58d4c1"
      },
      "source": [
        "data_fixed = data_fixed.drop('features')\n",
        "data_fixed.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------+----------+--------------------+--------------------+-------------------+----+-----+------------+-------------+-----------+--------------------+--------------------+--------------------+----------+\n",
            "|Review_ID|Rating|Year_Month|   Reviewer_Location|         Review_Text|             Branch|Year|Month|Branch_Clean|LocationIndex|BranchIndex|         word_tokens|                  tf|            sentence|prediction|\n",
            "+---------+------+----------+--------------------+--------------------+-------------------+----+-----+------------+-------------+-----------+--------------------+--------------------+--------------------+----------+\n",
            "|670772142|     4|    2019-4|           Australia|If you've ever be...|Disneyland_HongKong|2019|    4|    HongKong|          2.0|        2.0|[ever, disneyland...|(65536,[329,4756,...|[-0.0936634524935...|         1|\n",
            "|670682799|     4|    2019-5|         Philippines|Its been a while ...|Disneyland_HongKong|2019|    5|    HongKong|          5.0|        2.0|[since, last, tim...|(65536,[518,535,1...|[-0.0773864729230...|         1|\n",
            "|670623270|     4|    2019-4|United Arab Emirates|Thanks God it was...|Disneyland_HongKong|2019|    4|    HongKong|         12.0|        2.0|[thanks, god, was...|(65536,[329,2701,...|[-0.1203033038125...|         0|\n",
            "|670607911|     4|    2019-4|           Australia|HK Disneyland is ...|Disneyland_HongKong|2019|    4|    HongKong|          2.0|        2.0|[disneyland, grea...|(65536,[4167,4616...|[-0.2445185065139...|         0|\n",
            "|670607296|     4|    2019-4|      United Kingdom|the location is n...|Disneyland_HongKong|2019|    4|    HongKong|          1.0|        2.0|[location, city, ...|(65536,[5942,7805...|[-0.1485488251509...|         0|\n",
            "|670591897|     3|    2019-4|           Singapore|Have been to Disn...|Disneyland_HongKong|2019|    4|    HongKong|          6.0|        2.0|[disney, world, d...|(65536,[1581,1753...|[-0.3641256210908...|         0|\n",
            "|670585330|     5|    2019-4|               India|Great place! Your...|Disneyland_HongKong|2019|    4|    HongKong|          4.0|        2.0|[great, place, da...|(65536,[511,5462,...|[0.09901081625139...|         1|\n",
            "|670574142|     3|    2019-3|            Malaysia|Think of it as an...|Disneyland_HongKong|2019|    3|    HongKong|          8.0|        2.0|[think, intro, di...|(65536,[338,1753,...|[-0.1022285941269...|         0|\n",
            "|670571027|     2|    2019-4|           Australia|Feel so let down ...|Disneyland_HongKong|2019|    4|    HongKong|          2.0|        2.0|[feel, let, place...|(65536,[1753,2568...|[-0.1951149690384...|         0|\n",
            "|670570869|     5|    2019-3|               India|I can go on talki...|Disneyland_HongKong|2019|    3|    HongKong|          4.0|        2.0|[talking, disneyl...|(65536,[1119,2026...|[0.02514937772309...|         0|\n",
            "|670443403|     5|    2019-4|       United States|Disneyland never ...|Disneyland_HongKong|2019|    4|    HongKong|          0.0|        2.0|[disneyland, neve...|(65536,[4518,5451...|[-0.0551771334268...|         1|\n",
            "|670435886|     5|    2019-4|              Canada|We spent the day ...|Disneyland_HongKong|2019|    4|    HongKong|          3.0|        2.0|[spent, day, grow...|(65536,[535,1753,...|[0.00918977975663...|         1|\n",
            "|670376905|     4|    2019-4|           Australia|We spend two days...|Disneyland_HongKong|2019|    4|    HongKong|          2.0|        2.0|[spend, two, days...|(65536,[1198,6290...|[0.20164532202386...|         1|\n",
            "|670324965|     5|    2019-4|         Philippines|It was indeed the...|Disneyland_HongKong|2019|    4|    HongKong|          5.0|        2.0|[indeed, happiest...|(65536,[2623,5462...|[-0.1324599012732...|         1|\n",
            "|670274554|     5|    2018-9|           Australia|This place is HUG...|Disneyland_HongKong|2018|    9|    HongKong|          2.0|        2.0|[place, huge, def...|(65536,[2568,4959...|[-0.1534749871864...|         1|\n",
            "|670205135|     3|    2019-1|      United Kingdom|We brought ticket...|Disneyland_HongKong|2019|    1|    HongKong|          1.0|        2.0|[brought, tickets...|(65536,[1753,2692...|[-0.0954507313049...|         0|\n",
            "|670199487|     4|    2019-4|     Myanmar (Burma)|Its huge , not en...|Disneyland_HongKong|2019|    4|    HongKong|         84.0|        2.0|[huge, enough, vi...|(65536,[2860,4756...|[0.09199683107435...|         1|\n",
            "|670129921|     3|    2019-4|      United Kingdom|Around   60 per p...|Disneyland_HongKong|2019|    4|    HongKong|          1.0|        2.0|[around, per, per...|(65536,[338,1753,...|[-0.0584112953903...|         0|\n",
            "|670099231|     4|    2019-4|           Australia|It   s Disneyland...|Disneyland_HongKong|2019|    4|    HongKong|          2.0|        2.0|[disneyland, need...|(65536,[5462,9832...|[-0.2184356308542...|         1|\n",
            "|670033848|     5|   2018-11|           Hong Kong|There is nothing ...|Disneyland_HongKong|2018|   11|    HongKong|          9.0|        2.0|[nothing, say, ex...|(65536,[6346,7772...|[-0.0185285165905...|         0|\n",
            "+---------+------+----------+--------------------+--------------------+-------------------+----+-----+------------+-------------+-----------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "## Tree-Based Classifiers (Decision Tree, Random Forest)\n",
        "---\n",
        "\n",
        "Trying to predict the rating (1, 2, 3, 4, 5) is a multinomial classifications problem. We're going to see how well we can predict the rating using both a Decision Tree and Random Forest Classifiers.\n",
        "\n",
        "We're also going to train/test the models on two versions of our datasets with slightly different features! This will result in 4 total models (2x RT, 2x DT)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwfiduj4yDOv"
      },
      "source": [
        "# Creating dataset 1\n",
        "assembler = VectorAssembler(\n",
        "  inputCols=['Year',\n",
        "             'Month',\n",
        "             'BranchIndex'],\n",
        "              outputCol=\"features\")\n",
        "\n",
        "output = assembler.transform(data_fixed)\n",
        "final_data = output.select('features','Rating')\n",
        "\n",
        "# 70/30 train/test split\n",
        "train_data, test_data = final_data.randomSplit([0.7,0.3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating dataset 2 using our K-Means clustering\n",
        "assembler3 = VectorAssembler(\n",
        "  inputCols=['Year',\n",
        "             'Month',\n",
        "             'prediction',\n",
        "             'BranchIndex'],\n",
        "              outputCol=\"features\")\n",
        "\n",
        "output3 = assembler3.transform(data_fixed)\n",
        "final_data3 = output3.select('features','Rating')\n",
        "\n",
        "# 70/30 train/test split\n",
        "train_data3, test_data3 = final_data3.randomSplit([0.7,0.3])"
      ]
    },
    {
      "source": [
        "### Initialize models"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdQ63uee-wdd"
      },
      "source": [
        "# Use mostly defaults to make this comparison \"fair\"\n",
        "dtc = DecisionTreeClassifier(labelCol='Rating',featuresCol='features')\n",
        "rfc = RandomForestClassifier(labelCol='Rating',featuresCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-MiUqwiLAaE",
        "outputId": "3f7ab90b-f45b-4a38-e8f8-2d1600a647d8"
      },
      "source": [
        "# Set hyperparameters (Decision Tree)\n",
        "dtc.setMaxDepth(30)\n",
        "dtc.setMaxBins(32)\n",
        "\n",
        "# Set hyperparameters (Random Forest)\n",
        "rfc.setMaxDepth(30)\n",
        "rfc.setMaxBins(32)\n",
        "rfc.setNumTrees(500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier_16a8902ec8b4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "source": [
        "### Train Models"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckZ51zfa-wS4"
      },
      "source": [
        "# Train Decision Tree model -- 2x (on different data splits)\n",
        "dtc_model = dtc.fit(train_data)\n",
        "dtc_model3 = dtc.fit(train_data3)\n",
        "\n",
        "# Record predictions on test sets\n",
        "dtc_predictions = dtc_model.transform(test_data)\n",
        "dtc_predictions3 = dtc_model3.transform(test_data3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model- - 2x (on different data splits)\n",
        "rfc_model = rfc.fit(train_data)\n",
        "rfc_model3 = rfc.fit(train_data3)\n",
        "\n",
        "# Record predictions on test sets\n",
        "rfc_predictions = rfc_model.transform(test_data)\n",
        "rfc_predictions3 = rfc_model3.transform(test_data3)"
      ]
    },
    {
      "source": [
        "### Model Results"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7MRbY9j_Iug"
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"Rating\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phHFQIty_PPr"
      },
      "source": [
        "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
        "rfc_acc = acc_evaluator.evaluate(rfc_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6qagNR4_VkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02651b78-cf02-4c0f-d51e-3fc989d6b2fe"
      },
      "source": [
        "print(\"Here are the results!\")\n",
        "print('-'*80)\n",
        "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
        "print('-'*80)\n",
        "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
        "#print('-'*80)\n",
        "#print('A ensemble using GBT had an accuracy of: {0:2.2f}%'.format(gbt_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "--------------------------------------------------------------------------------\n",
            "A single decision tree had an accuracy of: 54.27%\n",
            "--------------------------------------------------------------------------------\n",
            "A random forest ensemble had an accuracy of: 54.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gfsQxykrlKO",
        "outputId": "e542f56c-3d79-4fa6-f178-d767fe06ef92"
      },
      "source": [
        "dtc_acc3 = acc_evaluator.evaluate(dtc_predictions3)\n",
        "rfc_acc3 = acc_evaluator.evaluate(rfc_predictions3)\n",
        "\n",
        "print(\"Here are the results!\")\n",
        "print('-'*80)\n",
        "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc3*100))\n",
        "print('-'*80)\n",
        "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc3*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the results!\n",
            "--------------------------------------------------------------------------------\n",
            "A single decision tree had an accuracy of: 53.34%\n",
            "--------------------------------------------------------------------------------\n",
            "A random forest ensemble had an accuracy of: 54.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc4ZugHnrsg3",
        "outputId": "6ed1ca9a-1782-4a8b-83f2-c3d9b411e2eb"
      },
      "source": [
        "print(rfc_model.featureImportances)\n",
        "print(rfc_model3.featureImportances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3,[0,1,2],[0.15384163958097158,0.16651018795900555,0.6796481724600228])\n",
            "(4,[0,1,2,3],[0.08663907617636457,0.08792418341963637,0.4543978833540674,0.37103885704993167])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}